---
title: "パソコン・情報公開"
author: 廣野秀樹
date: 2020-12-20 11:41:46 +0900
---

# 継承を想定した書面の作成と情報公開

## 2012年11月8日に開始したkk2020_11というGitHubリポジトリ，メインは「鬼滅の刃と弁護士列車編」：cloneからVSCode

:CATEGORIES: #GitHub #パソコン #情報公開 #被害者安藤文さん

　GitHubというネットサービス，前提となるGitという技術についてはインターネット上にも沢山の情報があると思います。書籍もかなり出回っているようですが，知識や経験をお持ちでない場合，情報が多すぎるということでネットでの検索は非効率で時間が掛かるとも思います。

　私がここで利用しているGitHubのアカウントはhirono2011となっており，来年には10年目を迎えることになるかと思います。正確なことは憶えていないのですが，ひと目で開始の時期がわかるようアカウント名にもリポジトリ名にも開始時点での年を入れるようにしています。

　今回，ご紹介するGitHubのリポジトリはkk2020_11となっています。開始時点の年月というかたちにしています。GitHubのリポジトリは要点さえつかめばとても簡単に作成できます。これまでも気に掛け，新規作成での遷移に踏み切ってきたのがリポジトリの肥大化，データ容量にあります。

　2012年11月8日に開始したkk2020_11というGitHubリポジトリは，同年12月20日の現時点において23MBとなっています。写真や音声動画などを含めしまうといっきに容量が増えてしまうのですが，テキストデータのみであれば，そう増えることはないと考えています。

　GitHubにはWindowsパソコンでGUIのアプリもありますが，私は慣れているコマンドラインのみで操作を行っています。パソコンの環境はLinux，ディストリビューションはUbuntuになります。Windows10ではWSL2でUbuntuを動かしています。

　以下はコマンドラインでの操作履歴になりますが，普段使っている環境とは変えるため，Linuxで新規ユーザを作成し，新規ユーザの権限でログイン，その状態でGitHubのリポジトリをクーロンしました。コマンド捜査はgit cloneになりますが複製の作成，実質はフォルダの丸ごとダウンロードになります。

　cloneでの宛先の指定は，git@github.com:hirono2011/kk2020_11.git　と，https://github.com/hirono2011/kk2020_11.git があります。

　前者はsshでの認証が必要となりますが，後者では更新にGitHubアカウントのパスワードが必要となります。逆にいえばデータの取得のみで，変更点をGitHubのサーバに反映しないのであれば，パスワードも不要でデータの取得ができます。

　サーバ上のGitHubのデータはリモートリポジトリともいうのですが，ローカルのリポジトリの変更点（コミット）をリモートに反映させるにはgit pushを行います。これは管理者である私のみの作業となっています。

　コミット時点での変更点を記録し続け，コマンド操作でいつでも前の状態に戻したり，過去の変更点を確認できるというのがGitの特徴であり，通常は共同開発で使われることが多く，分散型バージョン管理システムとも呼ばれています。

　私の知識と経験で断言はできないのですが，cloneしたフォルダ（リポジトリ）の直下に，.gitという隠しファイルのフォルダがあり，このフォルダ内でリポジトリの変更点を全て管理しているようです。逆にいえば，.git以外は，Git本体とは関わりのないただのフォルダとファイルになります。

　cloneしたフォルダはローカルリポジトリとなりますが，リモートリポジトリとの紐づけはgit remote -v というコマンドで確認できます。このリモートリポジトリは変更が可能ですし，.gitのフォルダ（ディレクトリとも）以外のファイル・フォルダを別にコピーするなどなんとでもなります。

　フォルダやファイルというデータが，アプリと一体化していないのがGitのあ使いやすさにもなると考えています。別にご説明が必要となりますが，私がメインで文章を作成しているテキストファイルも，アプリには依存しないもので，Wordのようなワープロソフトとはことなる種類のデータになります。

　テキストファイルのデータは文字情報のみになります。そのまま編集中のWordのファイルにコピペの貼り付けもできますが，文字コードと改行コードの違いがトラブルとなる場合もありますが，最近のWordだと自動で処理をしてくれ問題はでないかと思います。

　Wordのファイルをテキストファイルとして保存することもできますが，文字修飾などの情報は失われ印刷には適さないデータとなります。WordのファイルをPDFファイルとして保存することも出来ますが，容易ではないもののMarkdown形式のテキストファイルからPDFファイルを作成することもできます。

　Markdown形式のテキストファイルからPDFファイルを作成の前段階として，Texファイルを作成するという方法もあるのですが，いきなりPDFファイルを作成するのと違い，細かい書式の変更や文字情報の追加ができます。とても面倒な作業になるのですが，自分で雛形を作ってしまえば，コマンド1つで完了です。

　文字情報の追加というのは，告発状の表題部になるのですが，見出しや本文のみのPDFファイルであれば，Markdown形式のmdファイルからPDFファイルを一発に作成するスクリプトを実装済みです。それも見出しの目次付きとなっています。

　表題部をLaTeXの文法で作るとなると面倒があって，気力も起こらずまだとりかかっていないのですが，表題部のみをWordなりLibreOfficeなりで作成し，一緒に綴るのもありかと考えています。

```
~ ❯❯❯ sudo useradd -m kokuhatu
~ ❯❯❯ cd /home/kokuhatu/
/h/kokuhatu ❯❯❯ ls
/h/kokuhatu ❯❯❯ sudo su - kokuhatu
$ mkdir git
$ cd git
$ pwd
/home/kokuhatu/git
$ fish
Welcome to fish, the friendly interactive shell
Type `help` for instructions on how to use fish
kokuhatu@a66-XTe ~/git> git clone git@github.com:hirono2011/kk2020_11.git
Cloning into 'kk2020_11'...
The authenticity of host 'github.com (52.69.186.44)' can't be established.
RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.
Are you sure you want to continue connecting (yes/no/[fingerprint])? no
Host key verification failed.
fatal: Could not read from remote repository.

Please make sure you have the correct access rights
and the repository exists.
kokuhatu@a66-XTe ~/git [128]> git clone https://github.com/hirono2011/kk2020_11.git
Cloning into 'kk2020_11'...
remote: Enumerating objects: 300, done.
remote: Counting objects: 100% (300/300), done.
remote: Compressing objects: 100% (253/253), done.
remote: Total 300 (delta 56), reused 276 (delta 35), pack-reused 0
Receiving objects: 100% (300/300), 5.93 MiB | 4.52 MiB/s, done.
Resolving deltas: 100% (56/56), done.
kokuhatu@a66-XTe ~/git> ls
kk2020_11/
kokuhatu@a66-XTe ~/git> cd kk2020_11/
kokuhatu@a66-XTe ~/g/kk2020_11 (main)> ls
2020-08-01_告発状.docx  2020-08-01_告発状.txt  Obsidian/  README.md  dot-auto-git-push.sh*  org/
kokuhatu@a66-XTe ~/g/kk2020_11 (main)> git remote -v
origin  https://github.com/hirono2011/kk2020_11.git (fetch)
origin  https://github.com/hirono2011/kk2020_11.git (push)
kokuhatu@a66-XTe ~/g/kk2020_11 (main)> ls
2020-08-01_告発状.docx  2020-08-01_告発状.txt  Obsidian/  README.md  dot-auto-git-push.sh*  org/
kokuhatu@a66-XTe ~/g/kk2020_11 (main)> du -h
8.0K    ./Obsidian/01_鬼滅の刃と弁護士列車編/daily
8.0K    ./Obsidian/01_鬼滅の刃と弁護士列車編/apps
448K    ./Obsidian/01_鬼滅の刃と弁護士列車編/node
20K     ./Obsidian/01_鬼滅の刃と弁護士列車編/.obsidian
12K     ./Obsidian/01_鬼滅の刃と弁護士列車編/template
516K    ./Obsidian/01_鬼滅の刃と弁護士列車編
40K     ./Obsidian/kk_Obsidian/daily
8.0K    ./Obsidian/kk_Obsidian/apps
3.0M    ./Obsidian/kk_Obsidian/tweets
20K     ./Obsidian/kk_Obsidian/node
28K     ./Obsidian/kk_Obsidian/.obsidian
12K     ./Obsidian/kk_Obsidian/template
52K     ./Obsidian/kk_Obsidian/Blog投稿済み
260K    ./Obsidian/kk_Obsidian/source
52K     ./Obsidian/kk_Obsidian/md/再捜査の事実/請求に至る経緯/法律上の問題点
32K     ./Obsidian/kk_Obsidian/md/再捜査の事実/請求に至る経緯/法務省
36K     ./Obsidian/kk_Obsidian/md/再捜査の事実/請求に至る経緯/金沢地方検察庁
328K    ./Obsidian/kk_Obsidian/md/再捜査の事実/請求に至る経緯/金沢西警察署
452K    ./Obsidian/kk_Obsidian/md/再捜査の事実/請求に至る経緯
8.0K    ./Obsidian/kk_Obsidian/md/再捜査の事実/参考資料/弁護士
12K     ./Obsidian/kk_Obsidian/md/再捜査の事実/参考資料
16K     ./Obsidian/kk_Obsidian/md/再捜査の事実/情報公開のご説明
492K    ./Obsidian/kk_Obsidian/md/再捜査の事実
500K    ./Obsidian/kk_Obsidian/md
4.6M    ./Obsidian/kk_Obsidian
5.1M    ./Obsidian
8.0K    ./.git/refs/remotes/origin
12K     ./.git/refs/remotes
8.0K    ./.git/refs/heads
4.0K    ./.git/refs/tags
28K     ./.git/refs
6.0M    ./.git/objects/pack
4.0K    ./.git/objects/info
6.0M    ./.git/objects
56K     ./.git/hooks
4.0K    ./.git/branches
8.0K    ./.git/info
8.0K    ./.git/logs/refs/remotes/origin
12K     ./.git/logs/refs/remotes
8.0K    ./.git/logs/refs/heads
24K     ./.git/logs/refs
32K     ./.git/logs
6.2M    ./.git
684K    ./org/main
4.6M    ./org/reference
11M     ./org
23M     .
kokuhatu@a66-XTe ~/g/kk2020_11 (main)> 

```

　次がブラウザというかWeb上でのGitHubのkk2020_11リポジトリのページになります。

- hirono2011/kk2020_11: 2020年11月8日開始 https://t.co/ft2inEY9c5

　下向きの矢印のCodeというアイコンが見えますが，これをクリックするとメニューがでます。ZIPでのダウンロードもできますが，自動で内容が更新されることはないのでおすすめは出来ません。Gitのインストールがパソコンに必要となりますが，今は導入も容易かと思います。

　リポジトリのフォルダは階層構造で統合開発環境のプロジェクトのようになっています。それもあるので，個別にファイルを操作するよりは，高機能エディタの利用がおすすめです。Microsoftが開発しているVSCodeやGitHubが開発しているAtomがあり，横断的なテキスト検索が容易なのも特徴です。

- 2020-12-20-134527_kk2020_11　-　Visual　Studio　Code.jpg https://t.co/VqBzssPlNt

　スクリーンショットです。2,3，検索ワードを試したところ，「八坂神社」だと多すぎない数におさまりました。ファイル内ではなくフォルダ内のテキストファイルをすべて走査しているようですが，ほぼ一瞬で結果が反映されます。まさに神がかりといった感じです。

# プログラミング

## Emacs-Lispで，タイトルにファイル名を交えた投稿テキストを取得する自作コマンド

:CATEGORIES: #@kanazawabengosi #金沢弁護士会 #@JFBAsns #日本弁護士連合会（日弁連） #法務省 #@MOJ_HOUMU #Emacs #Emacs-Lisp

　Emacs-Lispのプログラミングもけっこうブランクがあったので，最悪，午前中いっぱいは時間を使いそうと思っていたのですが，思いがけずすんなりと行きました。これで告発状作成の作業効率も改善に期待が持ています。

>|lisp|
;;;;2017-08-24;;;;
(defun k-markdown-copy-to-subtree ()
  "Narrow buffer to the current subtree."
  (interactive)
  (save-excursion
  (let ((=start)(=end))
       (progn (markdown-back-to-heading-over-code-block t) (setq =start (point)))
       (progn (markdown-end-of-subtree)
	      (if (and (markdown-heading-at-point) (not (eobp)))
		  (backward-char 1))
	      (setq =end (point))(copy-region-as-kill =start =end)))))

;;2021-02-04
(defun k-markdown-copy-to-subtree ()
  "Narrow buffer to the current subtree."
  (interactive)
  (save-excursion
  (let ((=start)(=end))
       (progn (markdown-back-to-heading-over-code-block t) (setq =start (point)))
       (progn (markdown-end-of-subtree)
	      (if (and (markdown-heading-at-point) (not (eobp)))
		  (backward-char 1))
	      (setq =end (point))
	      (setq fname (file-name-nondirectory (buffer-file-name)))
	      (string-match ".+_\\(.+\\)\\.md" fname)
	      (setq fname (match-string 1 fname))
	      ;;(copy-region-as-kill =start =end)
	      ;; 指定した範囲のリージョンのテキストを変数に代入
	      (setq text (concat fname (buffer-substring-no-properties =start =end)))
	      (message fname)
	      ;; クリップボードに変数の内容を送る。
	      (x-set-selection nil text)
	      ))))
||<

　同名の関数ですが，後のものが上書きされて有効になります。以前のものは2017年8月24日となっていました。今回，追加した機能は，ファイル名の一部を見出しの先頭に追加するという処理です。

　例えば，「2020-12-11-152316_深澤諭史弁護士（第二東京弁護士会）.md」というのがファイル名で，「深澤諭史弁護士（第二東京弁護士会）」がテキストの抽出部分になります。正規表現を使っていますが，Emacs-Lispだとエスケープの数が増えます。

　テキストの取得は，「markdown-end-of-subtree」などというmarkdown-modeにある関数を呼び出して使っています。だいたいはキーマップに登録されているので，Emacsの場合，キーバインドから関数名と編集位置を簡単に探し出すことが出来ます。

## MySQLでデータ（レコード）の削除とオートインクリメントの番号の振り直し

:CATEGORIES: #@kanazawabengosi #金沢弁護士会 #@JFBAsns #日本弁護士連合会（日弁連） #法務省 #@MOJ_HOUMU

　どうもEmacs-Lispのx-set-selectionという関数は，コピーがそのままクリップボードを上書きせず，クリップボードの履歴を開いて選択肢直す必要があるようです。したがって間違った投稿をしてしまい，記事の削除とデータベースからのデータの削除を行いました。

　以前は，phpmyadminというアプリを使ってブラウザからデータベースの操作をすることが多かったのですが，どうも今回のUbuntuのシステムではインストールをしていなかったようです。

　phpmyadminは視覚的に簡単な操作ができるのですが，余り使うこともなく勉強にもならないので，直接，MySQLにログインして操作を行いました。操作を間違えると取り返しのつかないことにもなりかねないので，多少気が張ります。今後もありそうなので，メモを残しておきます。

>|sql|
mysql> DELETE FROM hatena201912 WHERE id = 1153;
Query OK, 1 row affected (0.01 sec)

mysql> ALTER TABLE hatena201912 AUTO_INCREMENT = 1153;
Query OK, 0 rows affected (0.01 sec)
Records: 0  Duplicates: 0  Warnings: 0
||<

## Ruby

### ヒアドキュメントをパイプ処理の入力とし，ワンライナーにファイル名を引数で渡し，置換でファイルの書き換え

:CATEGORIES: #Ruby

```
cat << 'EOS' | ruby -e 'File.write(ARGV[0], File.read(ARGV[0]).gsub(/(.*cond = http(.*\n)+?[ ]*fi\n)/, "\\1#{STDIN.read}"))' test.sh
  if ［ $cond = https ］;then
    port=443
  fi
EOS
```

- Rubyやsedで複数行の文章を任意の箇所に挿入する - grep Tips * [https://www.greptips.com/posts/1170/](https://www.greptips.com/posts/1170/)

　すごく勉強させてもらったページです。ヒアドキュメントは変数への代入に使うことが多く，パイプで出力を次のコマンド処理に渡したことはあったかもしれないですが，Rubyのワンライナーの処理でファイルの内容を書き換えるのに使っています。

　gsubメソッドの正規表現が複雑になっていますが，後方参照でヒアドキュメントの内容と文字列を連結させています。これはよく行ってきた処理で，正規表現の部分が単純であれば，よりわかりやすいかと思います。

　なぜかコピペで半角の鉤括弧が全角文字になっていることに気がついたので直しました。コピーしたコードはそのまま使えていました。最近は見かけないですが，文字を揃えるのに半角スペースを全角スペースに置き換えてあり，それでエラーが出ることは過去に経験があります。

　File.writeの引数に，スクリプトではなくワンライナーから引数を使っていますが，これは初めて知ったことで，この引数の関係でスクリプトにすることが過去に何度かありました。数が増えると管理が難しくなるというのがスクリプトの難点で，ワンライナーだと処理の内容も一目瞭然です。

　ちょっとした修正を加えて実行できるのもワンライナーの利便性かと思います。テキストファイルにコマンド履歴として保存し，catコマンドの出力からコピペで使うということは前からやっています。わかりやすくcというファイル名にしています。次のような感じです。


```
(py37_env) ➜  告発状2021 git:(main) ✗ cat c
rm *.{aux,log,pdf,tex,toc} tmp.txt

rm *.{aux,log,tex,toc} tmp.txt

for x in ./*.md; do md-to-tex-pandoc.rb $x; lualatex ${x%%md}tex; done; rm ./*{aux,log,tex,toc} tmp.txt
```

### RubyのARGFオブジェクトを使って，ディレクトリ内のzshグロブにマッチした全てのテキストファイルを正規表現で置換

:CATEGORIES: Ruby #正規表現

```
cat << 'EOS' | ruby -i -e 'puts ARGF.read.gsub(/(.*cond = http(.*\n)+?[ ]*fi\n)/, "\\1#{STDIN.read}")' test.sh
  if [ $cond = https ];then
    port=443
  fi
EOS
```

- Rubyやsedで複数行の文章を任意の箇所に挿入する - grep Tips * [https://www.greptips.com/posts/1170/](https://www.greptips.com/posts/1170/)

　ARGVはよく使いますが，ARGFというのは初めて見たように思います。もう15年以上はRubyを使っていると思いますが，今日まで知らなかったことが驚きです。上記のページのワンライナーで知りました。

　ARGFを調べたところ，引数を全てファイルとみなし連結して処理するような説明でしたが，Shiftで一つずつ取り出すという情報もあり，試したところ，ファイルグロブ（Windowsのワイルドカードと似たもの）で指定したファイルを1つずつ読み込んで処理をしているようでした。

　この理屈だとより強力なZshグロブで，ディレクトリ内のファイルを一括で置換できるのではと考え，やってみたところうまく行ったようです。これまではfindコマンドにexecオプションとsedの組み合わせなどの処理をしてきたように思いますが，より簡単に出来そうな感じです。

　次のようにやってみました。

>|sh|
(py37_env) ➜  ruby-2020-02-09 date > x.txt
(py37_env) ➜  ruby-2020-02-09 cat x.txt 
2021年  2月  9日 火曜日 15:50:04 JST
(py37_env) ➜  ruby-2020-02-09 cp x.txt dir*/
(py37_env) ➜  ruby-2020-02-09 cp x.txt dir*/dir*/dir*/
(py37_env) ➜  ruby-2020-02-09 ls **/x.txt
dir1/dir2/dir3/x.txt  dir1/x.txt  x.txt
(py37_env) ➜  ruby-2020-02-09 cat **/x.txt
2021年  2月  9日 火曜日 15:50:04 JST
2021年  2月  9日 火曜日 15:50:04 JST
2021年  2月  9日 火曜日 15:50:04 JST
(py37_env) ➜  ruby-2020-02-09 echo "追加のテスト" | ruby -i -e 'puts ARGF.read.gsub(/(^.+$)/, "\\1 -> #{STDIN.read}")' **/*.txt
(py37_env) ➜  ruby-2020-02-09 cat **/x.tx
2021年  2月  9日 火曜日 15:50:04 JST -> 追加のテスト

2021年  2月  9日 火曜日 15:50:04 JST -> 追加のテスト

2021年  2月  9日 火曜日 15:50:04 JST -> 追加のテスト

(py37_env) ➜  ruby-2020-02-09 readlink -f **/x.txt
/home/a66/w/ruby-2020-02-09/dir1/dir2/dir3/x.txt
/home/a66/w/ruby-2020-02-09/dir1/x.txt
/home/a66/w/ruby-2020-02-09/x.txt
||<

　処理を単純にするためechoコマンドを使いましたが，次のようにcatコマンドを使えば，テキストファイルの内容を追加することが簡単に出来ます。

>|sh|
(py37_env) ➜  ruby-2020-02-09 cat m | ruby -i -e 'puts ARGF.read.gsub(/(^.+$)/, "\\1 -> #{STDIN.read}")' **/*.txt
(py37_env) ➜  ruby-2020-02-09 cat **/x.txt
2021年  2月  9日 火曜日 15:50:04 JST -> 追加のテスト -> /home/a66/w/ruby-2020-02-09/dir1/dir2/dir3/x.txt
/home/a66/w/ruby-2020-02-09/dir1/x.txt
/home/a66/w/ruby-2020-02-09/x.txt


2021年  2月  9日 火曜日 15:50:04 JST -> 追加のテスト -> /home/a66/w/ruby-2020-02-09/dir1/dir2/dir3/x.txt
/home/a66/w/ruby-2020-02-09/dir1/x.txt
/home/a66/w/ruby-2020-02-09/x.txt


2021年  2月  9日 火曜日 15:50:04 JST -> 追加のテスト -> /home/a66/w/ruby-2020-02-09/dir1/dir2/dir3/x.txt
/home/a66/w/ruby-2020-02-09/dir1/x.txt
/home/a66/w/ruby-2020-02-09/x.txt
||<

### httpartyとfeedjiraで，BloggerのRSSを取得

:CATEGORIES: Ruby

>|ruby}
require 'httparty'
require 'feedjira'

url="https://kk2020-09.blogspot.com/feeds/posts/default?alt=rss&max-results=12"
xml = HTTParty.get(url).body
obj = Feedjira.parse(xml)
list = []
obj.entries.each do |item|
  list += [
    :title => item.title,
    :url => item.url,
    :title => item.summary,
    :published => item.published.to_time.strftime("%Y-%m-%d %H:%M:%S")
  ]
end

#上記のコードをirbに貼り付け，操作を継続
irb(main):149:0> list.size
=> 12
irb(main):150:0> list[0]
=> {:title=>"＼ystk　@lawkus＼インターネットに浸かって久しい現代においては社会を平板にしか見られない病気の人が大量に発生しているため、権力者がそこにつけ込むため「かわいそう", :url=>"https://kk2020-09.blogspot.com/2021/02/ystklawkus_12.html", :published=>"2021-02-12 04:33:00"}
irb(main):151:0> list[11]
=> {:title=>"REGEXP：”裁判官”／小倉秀夫（@chosakukenho）の検索（2020-09-29〜2021-02-11／2021年02月12日08時00分の記録46件）", :url=>"https://kk2020-09.blogspot.com/2021/02/regexpchosakukenho2020-09-292021-02.html", :published=>"2021-02-11 23:00:00"}

||<



# 長文の文字列から特定の文字列を抽出してその前後の文字列だけを取り出してデータに，というのをRubyでやってみる

:CATEGORIES: Ruby

>|ruby|
irb(main):020:0' 雑でいいならテキストファイルにしてから正規表現で検索かけるのが簡単だと思いますが，単語としてちゃんと取り出したいなら形態素解析する必要があると思います
irb(main):021:0' > @uwaaaa 雑でいいならテキストファイルabcdefgにしてから正規表現で検索かけるのが簡単だと思いますが，単語としてちゃんと取り出したいなら形態素解析する必要
があると思います 
irb(main):022:0> EOF
irb(main):023:0> n=str.index("正規表現")
irb(main):024:0> str[n-10..n-1]
=> "トファイルにしてから"
irb(main):025:0> n=str.index("正規表現", n+1)
irb(main):026:0> str[n-10..n-1]
=> "cdefgにしてから"
||<

　前後の行を含めて取得する方が実際的という気がしますが，長文を改行区切りで配列に入れ，検索にマッチした配列要素の前後をインデックス指定で取得すればいいような気がします。全文検索であればインデックスの最大値までの再帰処理になるかと思います。

## Rubyのmecabで形態素解析というのをやってみた（Linux）

:CATEGORIES: #Ruby #Linux

sudo apt install mecab
sudo apt install libmecab-dev
sudo apt install mecab-ipadic-utf8

gem install mecab
gem install natto

- [Ruby]mecabを使ってみた（形態素解析） - Qiita[https://qiita.com/hkengo/items/0c47675c86535bc85d1e](https://qiita.com/hkengo/items/0c47675c86535bc85d1e)

　上記のページを参考に，そのままコピペで実行してみました。形態素解析という言葉自体，今日初めて目にしたのですが，これは国語の勉強にもなりそうです。かなり人工知能的な感じです。

>|ruby|

||<

# 「過去のはてなダイアリーの検索」という参考記録資料について

:CATEGORIES: @kanazawabengosi #金沢弁護士会 @JFBAsns 日本弁護士連合会（日弁連） #法務省 @MOJ_HOUMU #説明

　「.hatena.hirono-hideki」というパソコンのフォルダになるのですが，1,370のテキストファイルがあり，データサイズは16MB，1,31443行のテキスト，286,849のワード，13,388,205文字となっています。

　ファイル名は，00801014 19641126 19920401 19920402 19920408 19920409 19920410 19920411 19920412 19920413から始まり，20150301 20150302 20150303 20150304 20150305 20150306 20150307 20150308 20150309 20150310で終わっています。

　これは独自の仕様であったはてなダイアリーの日付単位の記事に対応するもので，「19920401」は，1992年（平成4年）4月1日に対応します。そして最終が2015年3月10日です。00801014は意味のない内容だったので削除しました。

　都合よくファイルが年月日の順序で並んでいるので，検索結果に反映されるのですが，grep 弁護士 ./*　という検索の場合数値の若い古いものから並び，grep 弁護士 ./* |tac　とやると逆に新しいものから表示され，末尾に最も古いものが来ます。

　tacコマンドというのは滅多に見かけないので意味不明かと思いますが，catコマンドを逆順で表示させるものです。

- 【cat】Linuxでファイル内容を表示・作成・連結するコマンド | UX MILK https://t.co/i8GmlIqZFx

　この検索結果のテキストの内容をはてなブログに記事として投稿しています。今のところ次の3つの記事ですが，今後も活用することが多くなると思います。

```
(py37_env) ➜  .hatena.hirono-hideki ghatena201912 | grep -a '過去のはてなダイアリーの検索'
 - 1174：2021-02-11_13:59:47 被告発人古川龍一裁判官# 「古川龍一」（被告発人古川龍一裁判官）をキーワードにした過去のはてなダイアリーの検索 https://hirono-hideki.hatenadiary.jp/entry/2021/02/11/135946
 - 1175：2021-02-11_14:03:30 モトケンこと矢部善朗弁護士（京都弁護士会）# モトケンこと矢部善朗弁護士（京都弁護士会）に関する過去のはてなダイアリーの検索 https://hirono-hideki.hatenadiary.jp/entry/2021/02/11/140328
 - 1176：2021-02-11_14:19:51 市場急配センター# 2003年6月9日付け求意見書に関する，過去のはてなダイアリーの検索 https://hirono-hideki.hatenadiary.jp/entry/2021/02/11/141948
```

　記事を開いてみないとわからないと思いますが，四角い枠の中でテキストが，一部色付けで表示されているかと思います。これははてな記法のシンタックスハイライトという機能を使っているのですが，注意点は，行の折り返しがなく，下のスクロールバーで右に伸びていることです。

　文字制限のあるTwitterを始めてからこまめに改行を入れるようになったのですが，以前は改行をしないまま書き続けることが多く，一行に300文字を超えるものも少なくないことを確認しています。

　この行の折り返しというのは一長一短があるのですが，テキストをコピペし，ワープロソフトに貼り付ければ，自動で折り返しが入るかと思います。基本的に一行が1件の検索データとなっているかと思います。おすすめなのはブラウザでのページ内検索です。

　色付けは別に，折り返しがないのもHTMLのpreタグが使われているからになります。

- preタグとは｜コーディングのプロが作るHTMLタグ辞典 https://t.co/WWB3a6jgqa

　なお，過去のはてなダイアリーのデータでは，けっこうな数でHTMLタグが含まれたものがあり，見づらいことはあるかと思います。タグを除去する方法もあるのですが，HTMLとして表示させれば見やすくなることもあるかと思います。いずれにせよ，時期と内容確認に重点をおいています。

# 「過去のはてなダイアリーの検索」という参考記録資料について（修正・更新）

:CATEGORIES: @kanazawabengosi #金沢弁護士会 @JFBAsns 日本弁護士連合会（日弁連） #法務省 @MOJ_HOUMU #説明

>|sh|
N="蛸島"; grep "${N}" ./* |tac | perl -pe 's/\n/<\/li>\n/g'|sed -e '1s/^/<pre><ol>\n/'|sed '$a </ol><pre />\n'|sed -E 's/^\.\/([0-9]{8})/<li><span style="color: red"    >\1<\/span>/'|xsel -b; echo "「${N}」を過去のはてなダイアリーの記事から検索"
||<

- 奉納＼危険生物・弁護士脳汚染除去装置＼金沢地方検察庁御中_2020: 「蛸島」を過去のはてなダイアリーの記事から検索 https://t.co/2tJk4jaIzZ

　記事の投稿先もはてなブログからBloggerに変更しました。一番の理由は，はてなブログは一日あたりの投稿に文字数の制限があるからです。Bloggerも全くの無制限ではないと思いますし，リミットエラーが出たこともありますが，だいたいの限界も感覚がつかめています。

　そのBloggerでも過去に一度，いきなりブログを削除されたことがありました。イスラム国がGoogleに宣戦布告をしていたような時期でGoogleの社員に極度の警戒心もあったのでしょう。おそらく，APIからの投稿頻度が多すぎたため，いきなり爆撃のような処置をされたような感じでした。

　APIはBloggerよりはてなブログの方が使いやすくもあるのですが，はてなダイアリーでも投稿のリミットに掛かることがあり，警告もエラーもないまま記事の文字列が途中で途切れていました。Bloggerのようにエラーが出るよりやっかいなことです。

　それでもはてなブログは，外のブログサービスに比較すれば，リミットというか制限は許容量が大きいと思います。タイトルの文字数制限も気になったことがなく，コピペや引用を多用しない限りは，リミットに達することはないと思います。

　修正というのは，行の折り返しをさせたこと，HTMLタグで番号付をしたこと（見た目だけの番号），日付部分に赤色の色付けを行ったことぐらいです。スクリプトにすればいろいろとできるのですが，簡易的なワンライナーのままとしています。

　なお，日付部分の色付けですが，これは他にも使いみちがあるので，別に独立したご説明をさせてもらいます。

# 「過去のはてなダイアリーの記事から検索」のデータにある8文字の日付で，はてなブログを検索する方法

:CATEGORIES: @kanazawabengosi #金沢弁護士会 @JFBAsns 日本弁護士連合会（日弁連） #法務省 @MOJ_HOUMU

 - 奉納＼危険生物・弁護士脳汚染除去装置＼金沢地方検察庁御中_2020： 「蛸島」を過去のはてなダイアリーの記事から検索 https://kk2020-09.blogspot.com/2021/02/blog-post_12.html  

　上記の記事で実例を交えご説明をします。この「蛸島」をキーワードにした検索は，意外に数が少なくて6件となっていました。他にも意外だったのは，イワシの運搬やミールの説明に繰り返し使っていたと思う「蛸島丸」がなかったことです。

　検索結果のデータは上から日付の新しい順で並んでいます。20060903が1件，20060820が1件，20060726が4件とあります。20060903は，2006年9月3日の投稿を意味しますが，これはそのままテキストのファイル名ともなっています。

　私のアイディアでこのような拡張子もつけないファイル名としたのではなく，Emacsのパッケージが自動で作成するファイルでした。

　今はないはてなダイアリーというサービスですが，一見すると普通のブログではなるものの，記事を管理する仕組みが記事単位ではなく，日付単位で，その日付のファイルの中に記事があるという感じでした。なお，記事ではなくエントリーとも呼ばれていたと思います。

　偶然の発見ということも大きいのですが，この日付部分で検索をすると，当日の記事が探し出せることがわかりました。20060903の場合，次のようになります。はてなブログのページにある検索ボックスでの検索です。

- 20060903 の検索結果 - 告発＼金沢地方検察庁＼最高検察庁＼法務省＼石川県警察御中 https://t.co/OBTrqr4qnX

- hatena-diary_20060903 - 告発＼金沢地方検察庁＼最高検察庁＼法務省＼石川県警察御中 https://t.co/mIw2dgL9Og

　「hatena-diary_20060903」が記事名となっていますが，これははてなダイアリーにあった記事名ではなく，はてなブログにインポートする際に付けた記事名になると思います。

　記事には「[司法全般]刑務官、検察との関わり方」というような見出しがありますが，これが本来，はてなダイアリーのエントリー名になっていたものと思います。鉤括弧の中の文字列はカテゴリー分類の指定ともなっていました。

　ブラウザのページ内検索で「蛸島」を探すと，次のように該当する部分が一箇所だけありました。周辺を含め次に引用します。

```
実際の裁判例となると、検察官と弁護士が激しく対立し、接見という問題を含め弁護活動の妨害を受けたなどという例は、ずいぶん前からちょくちょく出ているようです。
　１０年ほど前に見た本になりそうなので、記憶の方もすこぶる曖昧ですが、お隣富山県の魚津市の警察署だったかでも類似の問題が取り沙汰されていたような憶えがあります。
　石川県でも過去には次のような例があるようです。これも判例を読んでいると解説等でちょくちょく見かける事件です。見方によれば、そのような時代背景も異なる陳腐な事例が取り沙汰されるほど、データが乏しいのかもしれません。
＜蛸島事件＞
http：//ja.wikipedia.org/wiki/%E8%9B%B8%E5%B3%B6%E4%BA%8B%E4%BB%B6
　比較的新しい事例で、私自身の事件捜査、裁判にも少なからぬ影響を及ぼしていると考えら得るのが、次の山中事件です。
＜山中事件＞
```

- hatena-diary_20060903 - 告発＼金沢地方検察庁＼最高検察庁＼法務省＼石川県警察御中 [https://hirono-hideki.hatenablog.com/entry/2018/09/20/135722](https://hirono-hideki.hatenablog.com/entry/2018/09/20/135722)

　「お隣富山県の魚津市の警察署だったかでも類似の問題」とあるのは，富山県の魚津市の警察署のことで，続いて出てくる蛸島事件と同様に，別冊ジュリストの記載でした。

　その蛸島事件については，ごく簡単に紹介され，Wikipediaのリンクがあり，リンクが有効であることを確認しましたが，当時とは内容に改変がある可能性もあるかと思います。2006年9月3日の時点で蛸島事件のWikipediaがあったというのも意外な発見でした。

　その蛸島事件より，注目していたのが続く，山中事件ですが，そこに書いてある通り，自費で購入した無罪事例集のような専門書で知った事件内容でした。今回の告発状では，優先度と時間の関係で踏み込まないようにしていますが，山中事件は同じ石川県の事件で，弁護団も共通があります。

　検索の方法は他も同じになると思いますので，必要に応じて活用して頂ければと思います。私が確認したかったのは，過去の記述内容のむら，取りこぼしの発見になるのですが，蛸島に関するものは予想よりはるかに少ないものでした。

```
(py37_env) ➜  .hatena.hirono-hideki N="蛸島港"; grep "${N}" ./* |tac | perl -pe 's/\n/<\/li>\n/g'|sed -e '1s/^/<pre><ol>\n/'|sed '$a </ol><pre />\n'|sed -E 's/^\.\/([0-9]{8})/<li><span style="color: red"    >\1<\/span>/'
(py37_env) ➜  .hatena.hirono-hideki N="飯田港"; grep "${N}" ./* |tac | perl -pe 's/\n/<\/li>\n/g'|sed -e '1s/^/<pre><ol>\n/'|sed '$a </ol><pre />\n'|sed -E 's/^\.\/([0-9]{8})/<li><span style="color: red"    >\1<\/span>/'
(py37_env) ➜  .hatena.hirono-hideki N="西海"; grep "${N}" ./* |tac | perl -pe 's/\n/<\/li>\n/g'|sed -e '1s/^/<pre><ol>\n/'|sed '$a </ol><pre />\n'|sed -E 's/^\.\/([0-9]{8})/<li><span style="color: red"    >\1<\/span>/'
<pre><ol>
<li><span style="color: red"    >20131118</span>:おととし１２月に長崎県西海市で起きたストーカー殺人事件や、先月、東京・三鷹市で起きた事件では、被害者や家族が事前に警察に相談していましたが、警察は差し迫った危険性はないと判断し、十分な対応を取っていませんでした。</li>
</ol><pre />
```

　蛸島港，飯田港の該当がなく，西海は1件の該当がありますが，「長崎県西海市で起きたストーカー殺人事件」で，私が目的とした石川県羽咋郡富来町（現在は志賀町に吸収合併）の西海港あるいは西海漁港のことです。

　告発の事実の記述で，優先度を高くしていたものですが，はてなダイアリーで記述がなかったというのは，全く意外な発見でした。

```
20060726：　彼女は珠洲市の出身で、蛸島町の隣の正院町だと聞いたかもしれません。私自身彼女の姿を見たことはありませんでした。その彼女と別れることになったらしく、途端に生活も派手になり、散財をするようになったようです。別れた理由についても、聞きもしないのに私に話していたことがありました。母娘の面倒を見ていたのに、誠意を裏切られたようなことをこぼしていました。
```

- 奉納＼危険生物・弁護士脳汚染除去装置＼金沢地方検察庁御中_2020： 「蛸島」を過去のはてなダイアリーの記事から検索 [https://kk2020-09.blogspot.com/2021/02/blog-post_12.html](https://kk2020-09.blogspot.com/2021/02/blog-post_12.html)

　上記が検索結果の3番目のデータになります。ブログの記事には3という番号が頭にありますが，引用したテキストにはありません。スクリプトを作成すれば，番号付もデータ数の集計も簡単に出来ます。

　上記の引用部分の，告発の事実として取り上げることを予定していました。引用部分に名前はないですが，内容をみれば誰のことなのかはすぐにわかりました。「途端に生活も派手になり、散財をするようになった」という部分は，ほとんど記憶が消えかけていたように思います。

　現在の記憶のまま記述というのを基本方針としてきたのですが，範囲が広すぎて絞り込みにも悩むところで，あいまいな記憶のままに違ったことを書けば，混乱や誤解にもなるかもしれないという危惧が出てきました。

　この先の告発の事実も現在の記憶が基本方針ですが，したつもりの記述がなかったという確認は大きな意味があると思います。また，重複する無駄もなるべく控え，限られた時間と労力の範囲で，質の高いものを作り上げたいと考えています。

# 過去のはてなダイアリーの検索まとめ記事，はてなブログへのリンクを追加

:CATEGORIES: @kanazawabengosi #金沢弁護士会 @JFBAsns 日本弁護士連合会（日弁連） #法務省 @MOJ_HOUMU

>|sh|
. ~/env.txt && egrep "${N}" ./* |tac | perl -pe 's/\n/<\/li>\n/g'|sed -e '1s/^/<pre><ol>\n/'|sed '$a </ol><pre />\n'|sed -E 's/^\.\/([0-9]{8})/<li><span style="color: red">\1<\/span>/' | sed -E 's#(([0-9]{4})([0-9]{2})([0-9]{2})</span>:)#\1[<a href="https://hirono-hideki.hatenablog.com/entry/\2/\3/\4/000000" target="_blank">link</a>] #g' > ~/tmp/egrep.txt; echo "arg-bpost.py \"「${N}」を過去のはてなダイアリーの記事から検索\""
||<

　 sed -E 's#(([0-9]{4})([0-9]{2})([0-9]{2})</span>:)#\1[<a href="https://hirono-hideki.hatenablog.com/entry/\2/\3/\4/000000" target="_blank">link</a>] #g'　が本日追加の部分です。

　. ~/env.txt　という部分は一昨日辺りの思いつきでした。コマンド履歴を簡潔にしたいというのが動機でした。テキストファイルの内容は次のようになっています。

```
(py37_env) ➜  .hatena.hirono-hideki cat ~/env.txt
export N="@motoken_tw.*(@hirono_hideki|@kk_hirono|@s_hirono)"
export N="安田敏.*妻"
export N="(元検|モトケン)"
export N="小倉秀夫(弁護士)?"
```

　上から並んでいますが，上書きで最後のものが有効になります。「. ~/env.txt」は，シェルへの環境変数の読み込みになります。ドットというコマンドですが，sourceという別名コマンドもあるかと思います。

【 source 】コマンド／【 . 】コマンド――シェルの設定を即座に反映させる：Linux基本コマンドTips（169） - ＠IT https://www.atmarkit.co.jp/ait/articles/1712/21/news015.html

　 ~/env.txtの編集はテキストエディタで行いますが，Vimが便利です。N="(元検|モトケン)"がNという変数への値の代入で，ワンライナーのコマンドでは，egrep "${N}"として参照しています。コマンドの履歴もそのままに，変数の値だけを変更して使い回しができます。

　このリンクを追加して2つ記事の投稿をしましたが，後のexport N="小倉秀夫(弁護士)?"の方は，[link]のあとに半角スペースを追加しました。「20080710:[link] *1215701367*[2008][弁護士]小倉秀夫弁護士VS元検弁護士？」な感じです。

- 2021年02月15日09時49分の登録： 「(元検|モトケン)」を過去のはてなダイアリーの記事から検索 [https://kk2020-09.blogspot.com/2021/02/blog-post_15.html](https://kk2020-09.blogspot.com/2021/02/blog-post_15.html)

- 2021年02月15日09時55分の登録： 「小倉秀夫(弁護士)?」を過去のはてなダイアリーの記事から検索 [https://kk2020-09.blogspot.com/2021/02/blog-post_86.html](https://kk2020-09.blogspot.com/2021/02/blog-post_86.html)

　どちらもちょっと見ただけですが，けっこう大きな発見がありました。「20080616:[link] 小倉秀夫弁護士の「全国医師連盟」批判について」とあるlinkの部分がはてなブログへのリンクになります。URLに日付情報の規則性があったから出来たことです。

# 
